{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1755125522613525\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "\n",
    "class LetterboxdScraper(BeautifulSoup):\n",
    "    def __init__(self, user, headers, base_url=\"https://letterboxd.com\"):\n",
    "        self.user = user\n",
    "        self.headers = headers\n",
    "        self.base_url = base_url\n",
    "        self.names = []\n",
    "        self.links = []\n",
    "        self.rating = []\n",
    "\n",
    "    def get_total_pages(self):\n",
    "        \"\"\"Obtém o número total de páginas de filmes do usuário.\"\"\"\n",
    "        response = requests.get(f\"{self.base_url}/{self.user}/films/page/1\", headers=self.headers)\n",
    "        super().__init__(response.text, 'html.parser')\n",
    "\n",
    "        # Verifica se a página não foi encontrada\n",
    "        if self.title and self.title.string == \"Letterboxd - Not Found\":\n",
    "            raise ValueError(\"Usuário não encontrado no Letterboxd.\")\n",
    "\n",
    "        paginate = self.find_all('li', {'class': 'paginate-page'})\n",
    "        if paginate:\n",
    "            # Obtém o número da última página\n",
    "            string = str(paginate[-1])\n",
    "            match = re.search(r'>(\\d+)<', string)\n",
    "            return int(match.group(1)) if match else 1\n",
    "        return 1\n",
    "\n",
    "    def scrape_page(self, page_number):\n",
    "        \"\"\"Faz o scrape de uma página específica e armazena os dados de filmes.\"\"\"\n",
    "        response = requests.get(f\"{self.base_url}/{self.user}/films/page/{page_number}\", headers=self.headers)\n",
    "        super().__init__(response.text, 'html.parser')\n",
    "\n",
    "        # Verifica se a página não foi encontrada\n",
    "        if self.title and self.title.string == \"Letterboxd - Not Found\":\n",
    "            raise ValueError(f\"Página {page_number} não encontrada para o usuário {self.user}.\")\n",
    "        \n",
    "        for item in self.find_all('li', {\"class\": \"poster-container\"}):\n",
    "            # Extraindo o nome do filme\n",
    "            name_match = re.search(r'img alt=\"(.*?)\"', str(item))\n",
    "            # Extraindo o link do filme\n",
    "            link_match = re.search(r'data-target-link=\"(.*?)\"', str(item))\n",
    "            # Extraindo nota do filme\n",
    "            rating_span = item.find('span', class_='rating')\n",
    "\n",
    "            if rating_span:\n",
    "                # Contar quantas estrelas existem no texto\n",
    "                num_stars = rating_span.text.count('★') + rating_span.text.count('½')/2\n",
    "                self.rating.append(num_stars)\n",
    "            else:\n",
    "                self.rating.append(None)\n",
    "\n",
    "            if name_match and link_match:\n",
    "                self.names.append(name_match.group(1))\n",
    "                self.links.append(f\"{self.base_url}{link_match.group(1)}\")\n",
    "\n",
    "    def scrape_all_pages(self):\n",
    "        \"\"\"Faz o scrape de todas as páginas de filmes do usuário usando múltiplas threads.\"\"\"\n",
    "        total_pages = self.get_total_pages()\n",
    "\n",
    "        def process_page(page):\n",
    "            self.scrape_page(page)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            list(executor.map(process_page, range(1, total_pages + 1)))\n",
    "\n",
    "    def to_dataframe(self):\n",
    "        \"\"\"Retorna os dados coletados como um DataFrame do pandas.\"\"\"\n",
    "        return pd.DataFrame({\n",
    "            \"Name\": self.names,\n",
    "            \"Ratings\": self.rating,\n",
    "            \"Link\": self.links\n",
    "        })\n",
    "\n",
    "    \n",
    "# Uso da classe\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    user = \"kizardas\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "    }\n",
    "    start = time.time() \n",
    "    scraper = LetterboxdScraper(user=user, headers=headers)\n",
    "    scraper.scrape_all_pages()\n",
    "    df = scraper.to_dataframe()\n",
    "    \n",
    "    # Opcional: salvar os dados em um arquivo CSV\n",
    "    df.to_csv(f\"data/{user}_data.csv\", index=False)  # Salva os dados em um arquivo CSV\n",
    "    end = time.time() \n",
    "    print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:11<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Definindo os cabeçalhos para a requisição\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.75 Safari/537.36\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "dta = pd.read_csv(\"data\\exorgravity_data.csv\")\n",
    "\n",
    "def fetch_data(row):\n",
    "    film_id, url = row\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        site = BeautifulSoup(response.text, 'html.parser')\n",
    "        response2 =  requests.get(url+\"fans/\", headers=HEADERS, timeout=10)\n",
    "        site2 = BeautifulSoup(response2.text, 'html.parser')\n",
    "\n",
    "        if 'Not Found' in str(site.title):\n",
    "            return film_id, None, None, None, None\n",
    "\n",
    "        # Extract data\n",
    "        try:\n",
    "            meta_string = str(site.find('meta', {'name': 'twitter:data2'}))\n",
    "            avr_rating = re.search(r'[0-9]\\.[0-9][0-9]', meta_string).group(0)\n",
    "        except:\n",
    "            avr_rating = None\n",
    "        \n",
    "        try:\n",
    "            year = re.findall(r\">([0-9]+)<\", str(site.findAll('div', {\"class\":\"releaseyear\"})[1]))[0]\n",
    "        except:\n",
    "            year = None\n",
    "        \n",
    "        try:\n",
    "            duration = re.search(r'[0-9]+', str(site.find('p', {'class': 'text-link text-footer'}))).group(0)\n",
    "        except:\n",
    "            duration = None\n",
    "\n",
    "        try:\n",
    "            genre_section = site.find('div', {'class': 'text-sluglist capitalize'})\n",
    "            genre = [x.text for x in genre_section.find_all('a')]\n",
    "        except:\n",
    "            genre = []\n",
    "\n",
    "        try:\n",
    "            lang = site.select_one('a[href^=\"/films/language\"]').text.strip()\n",
    "        except:\n",
    "            lang = None\n",
    "\n",
    "        try:\n",
    "            members = re.findall(r'title=\"([0-9,]+)',str(site2.findAll(\"li\", {\"class\":\"js-route-watches\"})[0]))[0]\n",
    "        except:\n",
    "            members = None\n",
    "        \n",
    "        try:\n",
    "            fans = re.findall(r'title=\"([0-9,]+)',str(site2.findAll(\"li\", {\"class\":\"js-route-fans\"})[0]))[0]\n",
    "        except:\n",
    "            fans = None\n",
    "\n",
    "        try:\n",
    "            likes = re.findall(r'title=\"([0-9,]+)',str(site2.findAll(\"li\", {\"class\":\"js-route-likes\"})[0]))[0]\n",
    "        except:\n",
    "            likes = None\n",
    "\n",
    "        try:\n",
    "            lists = re.findall(r'title=\"([0-9,]+)',str(site2.findAll(\"li\", {\"class\":\"js-route-lists\"})[0]))[0]\n",
    "        except:\n",
    "            lists = None\n",
    "\n",
    "        try:\n",
    "            reviews = re.findall(r'title=\"([0-9,]+)',str(site2.findAll(\"li\", {\"class\":\"js-route-reviews\"})[0]))[0]\n",
    "        except:\n",
    "            reviews = None\n",
    "\n",
    "        return film_id, avr_rating, year, duration, genre, lang, members, fans, likes, lists, reviews\n",
    "\n",
    "    except requests.RequestException:\n",
    "        return film_id, None, None, None, None, None, None, None, None, None, None, None\n",
    "\n",
    "\n",
    "# Run the function in parallel\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(tqdm(executor.map(fetch_data, dta.values), total=len(dta)))\n",
    "\n",
    "# Process results into DataFrame\n",
    "columns = ['Name', 'Avr_Rating', 'Year', 'Duration', 'Genre', 'Language', 'Members', 'Fans', 'Likes', 'Lists', 'Reviews']\n",
    "raw = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "print('Search completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Avr_Rating</th>\n",
       "      <th>Year</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Language</th>\n",
       "      <th>Members</th>\n",
       "      <th>Fans</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Lists</th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mufasa: The Lion King</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2024</td>\n",
       "      <td>118</td>\n",
       "      <td>[Family, Adventure, Animation]</td>\n",
       "      <td>English</td>\n",
       "      <td>238,700</td>\n",
       "      <td>293</td>\n",
       "      <td>51,426</td>\n",
       "      <td>35,336</td>\n",
       "      <td>88,050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smile 2</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2024</td>\n",
       "      <td>127</td>\n",
       "      <td>[Mystery, Horror]</td>\n",
       "      <td>English</td>\n",
       "      <td>596,171</td>\n",
       "      <td>1,604</td>\n",
       "      <td>158,432</td>\n",
       "      <td>106,604</td>\n",
       "      <td>210,972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speak No Evil</td>\n",
       "      <td>3.27</td>\n",
       "      <td>2024</td>\n",
       "      <td>110</td>\n",
       "      <td>[Horror, Thriller]</td>\n",
       "      <td>English</td>\n",
       "      <td>357,356</td>\n",
       "      <td>254</td>\n",
       "      <td>82,489</td>\n",
       "      <td>68,209</td>\n",
       "      <td>116,675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm Still Here</td>\n",
       "      <td>4.36</td>\n",
       "      <td>2024</td>\n",
       "      <td>137</td>\n",
       "      <td>[Drama, History]</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>287,222</td>\n",
       "      <td>8,448</td>\n",
       "      <td>178,666</td>\n",
       "      <td>66,373</td>\n",
       "      <td>125,246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Substance</td>\n",
       "      <td>3.82</td>\n",
       "      <td>2024</td>\n",
       "      <td>141</td>\n",
       "      <td>[Horror, Science Fiction]</td>\n",
       "      <td>English</td>\n",
       "      <td>2,114,043</td>\n",
       "      <td>21,961</td>\n",
       "      <td>740,536</td>\n",
       "      <td>354,296</td>\n",
       "      <td>794,337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Close</td>\n",
       "      <td>4.11</td>\n",
       "      <td>2022</td>\n",
       "      <td>104</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>French</td>\n",
       "      <td>384,220</td>\n",
       "      <td>11,023</td>\n",
       "      <td>160,143</td>\n",
       "      <td>91,458</td>\n",
       "      <td>111,279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Incantation</td>\n",
       "      <td>3.21</td>\n",
       "      <td>2022</td>\n",
       "      <td>111</td>\n",
       "      <td>[Horror]</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>178,124</td>\n",
       "      <td>1,267</td>\n",
       "      <td>37,697</td>\n",
       "      <td>31,794</td>\n",
       "      <td>43,286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ó Paí, Ó: Look at This</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2007</td>\n",
       "      <td>92</td>\n",
       "      <td>[Comedy, Music]</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>24,235</td>\n",
       "      <td>271</td>\n",
       "      <td>7,088</td>\n",
       "      <td>5,533</td>\n",
       "      <td>4,434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Carandiru</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2003</td>\n",
       "      <td>145</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>79,572</td>\n",
       "      <td>1,483</td>\n",
       "      <td>29,783</td>\n",
       "      <td>16,727</td>\n",
       "      <td>18,410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How to Lose a Guy in 10 Days</td>\n",
       "      <td>3.69</td>\n",
       "      <td>2003</td>\n",
       "      <td>116</td>\n",
       "      <td>[Comedy, Romance]</td>\n",
       "      <td>English</td>\n",
       "      <td>1,498,701</td>\n",
       "      <td>38,527</td>\n",
       "      <td>488,530</td>\n",
       "      <td>190,648</td>\n",
       "      <td>229,903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10 Things I Hate About You</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1999</td>\n",
       "      <td>97</td>\n",
       "      <td>[Comedy, Romance, Drama]</td>\n",
       "      <td>English</td>\n",
       "      <td>3,125,791</td>\n",
       "      <td>122,141</td>\n",
       "      <td>1,348,075</td>\n",
       "      <td>396,039</td>\n",
       "      <td>359,538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Central Station</td>\n",
       "      <td>4.31</td>\n",
       "      <td>1998</td>\n",
       "      <td>110</td>\n",
       "      <td>[Drama]</td>\n",
       "      <td>Portuguese</td>\n",
       "      <td>169,162</td>\n",
       "      <td>11,743</td>\n",
       "      <td>85,743</td>\n",
       "      <td>46,582</td>\n",
       "      <td>45,653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name Avr_Rating  Year Duration  \\\n",
       "0          Mufasa: The Lion King       2.90  2024      118   \n",
       "1                        Smile 2       3.27  2024      127   \n",
       "2                  Speak No Evil       3.27  2024      110   \n",
       "3                 I'm Still Here       4.36  2024      137   \n",
       "4                  The Substance       3.82  2024      141   \n",
       "5                          Close       4.11  2022      104   \n",
       "6                    Incantation       3.21  2022      111   \n",
       "7         Ó Paí, Ó: Look at This       3.78  2007       92   \n",
       "8                      Carandiru       4.10  2003      145   \n",
       "9   How to Lose a Guy in 10 Days       3.69  2003      116   \n",
       "10    10 Things I Hate About You       4.02  1999       97   \n",
       "11               Central Station       4.31  1998      110   \n",
       "\n",
       "                             Genre    Language    Members     Fans      Likes  \\\n",
       "0   [Family, Adventure, Animation]     English    238,700      293     51,426   \n",
       "1                [Mystery, Horror]     English    596,171    1,604    158,432   \n",
       "2               [Horror, Thriller]     English    357,356      254     82,489   \n",
       "3                 [Drama, History]  Portuguese    287,222    8,448    178,666   \n",
       "4        [Horror, Science Fiction]     English  2,114,043   21,961    740,536   \n",
       "5                          [Drama]      French    384,220   11,023    160,143   \n",
       "6                         [Horror]     Chinese    178,124    1,267     37,697   \n",
       "7                  [Comedy, Music]  Portuguese     24,235      271      7,088   \n",
       "8                          [Drama]  Portuguese     79,572    1,483     29,783   \n",
       "9                [Comedy, Romance]     English  1,498,701   38,527    488,530   \n",
       "10        [Comedy, Romance, Drama]     English  3,125,791  122,141  1,348,075   \n",
       "11                         [Drama]  Portuguese    169,162   11,743     85,743   \n",
       "\n",
       "      Lists  Reviews  \n",
       "0    35,336   88,050  \n",
       "1   106,604  210,972  \n",
       "2    68,209  116,675  \n",
       "3    66,373  125,246  \n",
       "4   354,296  794,337  \n",
       "5    91,458  111,279  \n",
       "6    31,794   43,286  \n",
       "7     5,533    4,434  \n",
       "8    16,727   18,410  \n",
       "9   190,648  229,903  \n",
       "10  396,039  359,538  \n",
       "11   46,582   45,653  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
